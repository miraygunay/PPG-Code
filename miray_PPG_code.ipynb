{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQCmFw4Nscf1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# 1. Veri Hazırlığı\n",
        "# PPG verisini yükle (veri dosyasının yolunu güncelleyin)\n",
        "data = pd.read_csv('ppg_dataset.csv')\n",
        "\n",
        "# Veri ön işleme\n",
        "X = data.drop('label', axis=1).values\n",
        "y = data['label'].values\n",
        "\n",
        "# Veriyi normalleştir\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Veriyi yeniden şekillendir (1D veriyi 2D veriye dönüştür)\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Veriyi eğitim ve test setlerine ayır\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. CNN Modelini Oluşturma\n",
        "model = Sequential([\n",
        "    Conv1D(64, 3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    MaxPooling1D(2),\n",
        "    Conv1D(128, 3, activation='relu'),\n",
        "    MaxPooling1D(2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Modeli derle\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 3. Modeli Eğitme\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# 4. Modeli Değerlendirme\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred_classes))\n",
        "print(confusion_matrix(y_test, y_pred_classes))\n",
        "\n",
        "# Eğitim ve doğrulama kaybı/grafiği çizimi (isteğe bağlı)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}